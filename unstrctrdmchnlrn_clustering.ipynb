{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Clustering Costco Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliverable 1: Preprocessing the Data for PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the costco_data.csv and demographic datasets.\n",
    "file_path=\"../Resources/.CSV OR DATABASE CONNECTION/PATH\"\n",
    "file_path=\"../Resources/.CSV OR DATABASE CONNECTION/PATH\"\n",
    "costco_df=pd.read_csv(file_path, index_col=0)\n",
    "costco_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coscto_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep all the LOCATIONS THAT HAVE A HEARING CENTER.\n",
    "coscto_df.drop(coscto_df[coscto_df[\"? COSTCO LOCATION YES\"] == False].index, inplace=True)\n",
    "#len(crypto_df.index)\n",
    "coscto_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the \"COSTCO LOCATION YES\" column. \n",
    "coscto_df = coscto_df.drop(['? COSTCO LOCATION YES'], axis=1)\n",
    "coscto_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows that have at least 1 null value.\n",
    "coscto_df = coscto_df.dropna()\n",
    "coscto_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the rows where AGE IS WITHIN THE RANGE WE ARE TARGETING.\n",
    "coscto_df = coscto_df.loc[coscto_df['? AGE COLUMNS'] != 0]\n",
    "coscto_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coscto_df = coscto_df.loc[coscto_df['? AGE COLUMNS'] > 0]\n",
    "crypto_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coscto_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame that holds only the ??ZIPCODE??\n",
    "coscto_name_df = coscto_df.iloc[: , [0]].copy()\n",
    "coscto_name_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the '?? ZIPCODE' column since it's not going to be used on the clustering algorithm.\n",
    "coscto_df = coscto_df.drop(['?? ZIPCODE'], axis=1)\n",
    "coscto_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use get_dummies() to create variables for text features.\n",
    "X=pd.get_dummies(coscto_df, columns=[\"   \", \"   \"])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data with StandardScaler().\n",
    " # 1. Create instance of StandardScaler\n",
    "data_scaler=StandardScaler()\n",
    "\n",
    "# 2. train scaler and transform the data\n",
    "X=data_scaler.fit_transform(X)\n",
    "\n",
    "# 3. preview the scaled data\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliverable 2: Reducing Data Dimensions Using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using PCA to reduce dimension to three principal components.\n",
    "# 1.  Initialize PCA model\n",
    "pca=PCA(n_components=3)\n",
    "\n",
    "# 2. Get 3 principal components the data.\n",
    "X_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the three principal components.\n",
    "pcs_df = pd.DataFrame(\n",
    "    data=X_pca, index=coscto_name_df.index, columns=[\"PC 1\", \"PC 2\", \"PC 3\"])\n",
    "pcs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliverable 3: Clustering Crytocurrencies Using K-Means\n",
    "\n",
    "#### Finding the Best Value for `k` Using the Elbow Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an elbow curve to find the best value for K.\n",
    "# 1.  Find the best value for K\n",
    "inertia = []\n",
    "k = list(range(1, 11))\n",
    "\n",
    "# 2. Calculate the inertia for the range of K values\n",
    "for i in k:\n",
    "    km = KMeans(n_clusters=i, random_state=0)\n",
    "    km.fit(pcs_df)\n",
    "    inertia.append(km.inertia_)\n",
    "    \n",
    "# 3. Create the elbow curve\n",
    "elbow_data = {\"k\": k, \"inertia\": inertia}\n",
    "df_elbow = pd.DataFrame(elbow_data)\n",
    "df_elbow.hvplot.line(x=\"k\", y=\"inertia\", xticks=k, title=\"Elbow Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running K-Means with `k=4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the K-Means model.\n",
    "model = KMeans(n_clusters=3, random_state=0)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(pcs_df)\n",
    "\n",
    "# Predict clusters\n",
    "predictions = model.predict(pcs_df)\n",
    "\n",
    "# Add the predicted class columns\n",
    "pcs_df[\"class\"] = model.labels_\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame including predicted clusters and coscto features.\n",
    "# Concatentate the coscto_df and pcs_df DataFrames on the same columns.\n",
    "clustered_df = pd.DataFrame(data = coscto_df, index = coscto_df.index)\n",
    "clustered_df[\"PC 1\"] = pcs_df[\"PC 1\"]\n",
    "clustered_df[\"PC 2\"] = pcs_df[\"PC 2\"]\n",
    "clustered_df[\"PC 3\"] = pcs_df[\"PC 3\"]\n",
    "\n",
    "\n",
    "#  Add a new column, \"?? ZIPCODE\" to the clustered_df DataFrame that holds the names of the cryptocurrencies. \n",
    "clustered_df[\"?? ZIPCODE\"] = coscto_name_df[\"?? ZIPCODE\"]\n",
    "\n",
    "#  Add a new column, \"Class\" to the clustered_df DataFrame that holds the predictions.\n",
    "clustered_df[\"?? ZIPCODE\"] = model.labels_\n",
    "\n",
    "# Print the shape of the clustered_df\n",
    "print(clustered_df.shape)\n",
    "clustered_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliverable 4: Visualizing Coscto Results\n",
    "\n",
    "#### 3D-Scatter with Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a 3D-Scatter with the PCA data and the clusters\n",
    "fig=px.scatter_3d(clustered_df, x=\"PC 1\", \n",
    "                  y=\"PC 2\", z=\"PC 3\", \n",
    "                  color=\"Class\", symbol=\"Class\", \n",
    "                  hover_name=\"?? ZIPCODE\", hover_data=[\"    \"], \n",
    "                  width=800)\n",
    "fig.update_layout(legend=dict(x=0, y=1))\n",
    "fig.show()\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table with POSSIBLE COSTCO LOCATION.\n",
    "clustered_df.hvplot.table(columns=['?? ZIPCODE', '  ', '  ', '  ', 'Class'],\n",
    "                         sortable=True, selectable=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the total number of with POSSIBLE COSTCO LOCATION.\n",
    "print(\"?? There are\", clustered_df.shape[0], \"with POSSIBLE COSTCO LOCATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data to create the scatter plot with POSSIBLE COSTCO LOCATION.\n",
    " # 1. Create instance of MinMaxScaler\n",
    "X = pd.DataFrame(clustered_df, columns=['    ', '    '], index = clustered_df.index)\n",
    "\n",
    "# 2. train scaler and transform the data\n",
    "X_scaled = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "# 3. preview the scaled data\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame that has the scaled data with the clustered_df DataFrame index.\n",
    "plot_df = pd.DataFrame(X_scaled, columns=['TotalCoinSupply', 'TotalCoinsMined'], \n",
    "                       index = costco_df.index)\n",
    "\n",
    "\n",
    "# Add the \"?? ZIPCODE\" column from the clustered_df DataFrame to the new DataFrame.\n",
    "plot_df['?? ZIPCODE'] = clustered_df['?? ZIPCODE']\n",
    "\n",
    "# Add the \"Class\" column from the clustered_df DataFrame to the new DataFrame. \n",
    "plot_df['Class'] = clustered_df['Class']\n",
    "\n",
    "plot_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hvplot.scatter plot using x=\"    \" and y=\"    \".\n",
    "plot_df.hvplot.scatter(x=\"   \", y=\"  \", hover_cols=[\"?? ZIPCODE\"], by=\"Class\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
